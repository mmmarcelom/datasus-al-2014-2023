{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o projeto, vamos utilizar a biblioteca PySUS criada por fccoelho.\n",
    "\n",
    "Mais informações podem ser encontradas através dos links abaixo:\n",
    "\n",
    "Github:  \n",
    "https://github.com/AlertaDengue/PySUS\n",
    "\n",
    "Documentação:  \n",
    "https://pysus.readthedocs.io/en/latest/tutorials.html#working-with-sih-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar o download, precisaremos das seguintes bibliotecas e métodos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysus.online_data.SIH import download\n",
    "from pysus.online_data import parquets_to_dataframe\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o dataset é muito grande e só utilizaremos algumas colunas no projeto, vamos primeiro listar e escolher as colunas que serão utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz download de um pequeno subset dos dados (escolhi arbitrariamente jan/2015).\n",
    "df_test = parquets_to_dataframe(download(states='AL', years=2015, months=1))\n",
    "\n",
    "# Cria uma lista de listas com os nomes das colunas, visto que usaremos a função writerows.\n",
    "lista = [[coluna] for coluna in df_test.columns.tolist()]\n",
    "\n",
    "# Cria um csv com os nomes das colunas.\n",
    "with open('nome_colunas.csv', 'w', newline='') as arquivo:\n",
    "    csv_writer = csv.writer(arquivo)\n",
    "    csv_writer.writerows(lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após analizar as colunas, foram escolhidas as seguintes colunas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = [\n",
    "    'UF_ZI',\n",
    "    'ANO_CMPT',\n",
    "    'MES_CMPT',\n",
    "    'CEP',\n",
    "    'MUNIC_RES',\n",
    "    'SEXO',\n",
    "    'IDADE',\n",
    "    'CID_NOTIF',\n",
    "    'VAL_TOT'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe agora possuí 1183143 linhas.\n",
      "\n",
      "Iniciando download: 12/2020... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1196872 linhas.\n",
      "\n",
      "Iniciando download: 1/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1209609 linhas.\n",
      "\n",
      "Iniciando download: 2/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1223606 linhas.\n",
      "\n",
      "Iniciando download: 3/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1237138 linhas.\n",
      "\n",
      "Iniciando download: 4/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1251502 linhas.\n",
      "\n",
      "Iniciando download: 5/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1265946 linhas.\n",
      "\n",
      "Iniciando download: 6/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1279585 linhas.\n",
      "\n",
      "Iniciando download: 7/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1294128 linhas.\n",
      "\n",
      "Iniciando download: 8/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1307371 linhas.\n",
      "\n",
      "Iniciando download: 9/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1321125 linhas.\n",
      "\n",
      "Iniciando download: 10/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1335641 linhas.\n",
      "\n",
      "Iniciando download: 11/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1348995 linhas.\n",
      "\n",
      "Iniciando download: 12/2021... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1362279 linhas.\n",
      "\n",
      "Iniciando download: 1/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1375133 linhas.\n",
      "\n",
      "Iniciando download: 2/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1387937 linhas.\n",
      "\n",
      "Iniciando download: 3/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1401783 linhas.\n",
      "\n",
      "Iniciando download: 4/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1414837 linhas.\n",
      "\n",
      "Iniciando download: 5/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1427458 linhas.\n",
      "\n",
      "Iniciando download: 6/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1439666 linhas.\n",
      "\n",
      "Iniciando download: 7/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1453271 linhas.\n",
      "\n",
      "Iniciando download: 8/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1467489 linhas.\n",
      "\n",
      "Iniciando download: 9/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1481521 linhas.\n",
      "\n",
      "Iniciando download: 10/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1496114 linhas.\n",
      "\n",
      "Iniciando download: 11/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1510622 linhas.\n",
      "\n",
      "Iniciando download: 12/2022... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1524566 linhas.\n",
      "\n",
      "Iniciando download: 1/2023... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1538900 linhas.\n",
      "\n",
      "Iniciando download: 2/2023... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1550537 linhas.\n",
      "\n",
      "Iniciando download: 3/2023... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1563765 linhas.\n",
      "\n",
      "Iniciando download: 4/2023... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1575935 linhas.\n",
      "\n",
      "Iniciando download: 5/2023... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1589033 linhas.\n",
      "\n",
      "Iniciando download: 6/2023... Download realizado com sucesso.\n",
      "Dataframe agora possuí 1602663 linhas.\n",
      "\n",
      "Iniciando download: 7/2023... Download realizado com sucesso.\n",
      "Erro.\n",
      "Iniciando download: 8/2023... Download realizado com sucesso.\n",
      "Erro.\n",
      "Iniciando download: 9/2023... Download realizado com sucesso.\n",
      "Erro.\n",
      "Iniciando download: 10/2023... Download realizado com sucesso.\n",
      "Erro.\n",
      "Iniciando download: 11/2023... Download realizado com sucesso.\n",
      "Erro.\n",
      "Iniciando download: 12/2023... Download realizado com sucesso.\n",
      "Erro.\n",
      "Download concluído\n",
      "Erros: 6\n"
     ]
    }
   ],
   "source": [
    "df_consolidado = pd.DataFrame()\n",
    "erros = []\n",
    "\n",
    "for ano in range(2014, 2023+1): # +1 visto que o método range() é não inclusivo\n",
    "    for mes in range(1,12+1):\n",
    "        print(f'Iniciando download: {mes}/{ano}...', end=' ')\n",
    "        \n",
    "        try:\n",
    "            dados = download(states='AL', years=ano, months=mes)\n",
    "            print(f'Download realizado com sucesso.')\n",
    "\n",
    "            # Converte os dados baixados em um dataframe\n",
    "            df = parquets_to_dataframe(dados)\n",
    "\n",
    "            # Filtra apenas as colunas \n",
    "            df = df[colunas] \n",
    "            \n",
    "            # Adiciona novos dados ao final\n",
    "            df_consolidado = pd.concat([df_consolidado, df])\n",
    "            \n",
    "            print(f'Dataframe agora possuí {df_consolidado.shape[0]} linhas.\\n')\n",
    "\n",
    "        except:\n",
    "            erros.append(f'{mes}/{ano}')\n",
    "            print('Erro.')\n",
    "        \n",
    "print('Download concluído')\n",
    "print(f'Erros: {len(erros)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7/2023', '8/2023', '9/2023', '10/2023', '11/2023', '12/2023']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consolidado.to_csv('SIH_SUS_AL-2014-2023.csv', sep=',', encoding='utf-8', index=False)\n",
    "# df_consolidado.to_csv('SIH_SUS_AL-2014-2023.csv', sep=',', encoding='utf-8', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso você tenha algum problema em realizar o download dessa forma, também é possível fazer o download de todos os arquivos dbc e converte-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_ZI</th>\n",
       "      <th>ANO_CMPT</th>\n",
       "      <th>MES_CMPT</th>\n",
       "      <th>ESPEC</th>\n",
       "      <th>CGC_HOSP</th>\n",
       "      <th>N_AIH</th>\n",
       "      <th>IDENT</th>\n",
       "      <th>CEP</th>\n",
       "      <th>MUNIC_RES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270000</td>\n",
       "      <td>2022</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>12200259000912</td>\n",
       "      <td>2722101303878</td>\n",
       "      <td>1</td>\n",
       "      <td>57480000</td>\n",
       "      <td>270240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270000</td>\n",
       "      <td>2022</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>12200259000912</td>\n",
       "      <td>2722101303889</td>\n",
       "      <td>1</td>\n",
       "      <td>57480000</td>\n",
       "      <td>270240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270000</td>\n",
       "      <td>2022</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td></td>\n",
       "      <td>2722106423564</td>\n",
       "      <td>1</td>\n",
       "      <td>57048076</td>\n",
       "      <td>270430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270000</td>\n",
       "      <td>2022</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td></td>\n",
       "      <td>2722106424202</td>\n",
       "      <td>1</td>\n",
       "      <td>57060190</td>\n",
       "      <td>270430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270000</td>\n",
       "      <td>2022</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td></td>\n",
       "      <td>2722106424213</td>\n",
       "      <td>1</td>\n",
       "      <td>57545000</td>\n",
       "      <td>270330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UF_ZI ANO_CMPT MES_CMPT ESPEC        CGC_HOSP          N_AIH IDENT  \\\n",
       "0  270000     2022       01    02  12200259000912  2722101303878     1   \n",
       "1  270000     2022       01    02  12200259000912  2722101303889     1   \n",
       "2  270000     2022       01    01                  2722106423564     1   \n",
       "3  270000     2022       01    01                  2722106424202     1   \n",
       "4  270000     2022       01    01                  2722106424213     1   \n",
       "\n",
       "        CEP MUNIC_RES  \n",
       "0  57480000    270240  \n",
       "1  57480000    270240  \n",
       "2  57048076    270430  \n",
       "3  57060190    270430  \n",
       "4  57545000    270330  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pysus.utilities.readdbc as dbc\n",
    "df = dbc.read_dbc('dbc_files/RDAL2201.dbc')\n",
    "df = df[colunas]\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
